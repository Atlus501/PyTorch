{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Atlus501/PyTorch/blob/main/computerVision_stripped.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will record the section for computer vision problems.\n",
        "\n",
        "Object detection - \"Where's the thing we're looking for?\"\n",
        "\n",
        "Segmentation - \"What are the different sections in this image?\"\n",
        "\n",
        "The model that does this is often called a convolutional neural network (CNN)\n",
        "\n",
        "*torch vision - base domain library\n",
        "\n",
        "*torchvisioin.datasets - datasets and data loading functions for cv\n",
        "\n",
        "*torchvision.transforms - functions for manipulating your vision data\n",
        "\n",
        "*torch.utils.data.Dataset - base dataset class for PyTorch\n",
        "\n",
        "*torch.utils.data.DataLoader - creates a python iterable over a dataset"
      ],
      "metadata": {
        "id": "uu1CL8gDlJ36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#0. CV in python\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "n_6fbzLhlJ4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "#download helper functions from learn pytorch repo\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)\n",
        "\n",
        "from helper_functions import accuracy_fn, print_train_time\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "#two of the main things you'll want to\n",
        "#track are the model's prformance and how fast it runs\n",
        "#but there is often a trade off between these tow metrics\n",
        "\n",
        "#the below libarry provides a fast, extensible progress bar for loops nd other iterable operations\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "X7TPPWa8lJ4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup training data\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\", #where to download the data\n",
        "    train=True, #do we want this training dataset\n",
        "    download=True, #do we want to download yes/no\n",
        "    transform=ToTensor(), #how do we want to transform the data\n",
        "    target_transform=None #how do we want to transform the labels/targets\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")"
      ],
      "metadata": {
        "id": "QWWTNPzplJ4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#see the first raining example\n",
        "image = train_data[0][0]\n",
        "#plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "#plt.show()\n",
        "image.shape"
      ],
      "metadata": {
        "id": "23inSykflJ4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataloader would turn our dataset into a Python iterable\n",
        "#split the data into mini-batches beccause it would be more computationall yefficient.\n",
        "#it would also give our neural network more chances to update its gradient per epoch.\n",
        "\n",
        "Batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(dataset= train_data, batch_size= Batch_size, shuffle= True)\n",
        "test_dataloader = DataLoader(dataset= test_data, batch_size= Batch_size, shuffle= True)\n",
        "\n",
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))"
      ],
      "metadata": {
        "id": "JeP8I5gSlJ4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build a baseline model\n",
        "flatten_model = nn.Flatten()\n",
        "\n",
        "x = train_features_batch[0]\n",
        "\n",
        "output = flatten_model(x) #perfor the forward pass"
      ],
      "metadata": {
        "id": "YwcIdcVOlJ4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class fashionModel(nn.Module):\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "        nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_stack(x)"
      ],
      "metadata": {
        "id": "9-Y--OLFlJ4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model_0 = fashionModel(input_shape=784, hidden_units=10, output_shape=10)\n",
        "\n",
        "#setup loss function, optimizer, and evaluation matrices\n",
        "loss_fn = nn.CrossEntropyLoss() #working with multi-class data\n",
        "#optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)\n",
        "\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "#download helper functions from learn pytorch repo\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ],
      "metadata": {
        "id": "2Af_eueFlJ4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import accuracy_fn, print_train_time\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "#two of the main things you'll want to\n",
        "#track are the model's prformance and how fast it runs\n",
        "#but there is often a trade off between these tow metrics\n",
        "\n",
        "#the below libarry provides a fast, extensible progress bar for loops nd other iterable operations\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "train_time_start_on_cpu = timer()\n",
        "\n",
        "epochs = 0\n",
        "\n",
        "#this setup will update our model once per batch rather than once per epoch\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n-------\")\n",
        "  train_loss = 0\n",
        "\n",
        "  #add a loop to loop through training batches\n",
        "  for batch, (X, y) in enumerate(train_dataloader):\n",
        "    model_0.train()\n",
        "\n",
        "    #1 Forward pass\n",
        "    y_pred = model_0(X)\n",
        "\n",
        "    #2 Calcualte loss on one batch of data\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "\n",
        "    #3 Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #4 loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    #5 optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "#the below evaluates the performance of the model\n",
        "test_loss, test_acc = 0,0\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  for X, y in test_dataloader:\n",
        "    test_pred = model_0(X)\n",
        "    test_loss += loss_fn(test_pred, y)\n",
        "    test_acc += accuracy_fn(y_true = y, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "  test_loss /= len(test_dataloader)\n",
        "  test_acc /= len(test_dataloader)\n",
        "\n",
        "  print(f\"Loss: {test_loss}. Accuracy: {test_acc}\")\n",
        "\n",
        "#evaluates the total training time of the model\n",
        "train_time_end_on_cpu = timer()\n",
        "total_train_time_on_cpu = train_time_end_on_cpu - train_time_start_on_cpu\n",
        "print(f\"Total training time: {total_train_time_on_cpu}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "7L7NP4VmlJ4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Make predictions and get model 0 results\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               device):\n",
        "  #reurns a ductionary contianing the results of model predicting on data_laoder\n",
        "  loss, acc = 0,0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X, y in data_loader:\n",
        "\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      y_pred = model(X)\n",
        "\n",
        "      loss += loss_fn(y_pred, y)\n",
        "      acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "    loss /= len(data_loader)\n",
        "    acc /= len(data_loader)\n",
        "\n",
        "  return {\"model_name\": model.__class__.__name__,\n",
        "          \"model_loss\": loss.item(),\n",
        "          \"model_acc\": acc}"
      ],
      "metadata": {
        "id": "hhQqV6wzlJ4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set up device agnostic code\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "#below is a computer vision model that attempts to use non-linearality\n",
        "class FashionModel_V2(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape: int,\n",
        "               hidden_units: int,\n",
        "               output_shape: int):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "        nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_stack(x)"
      ],
      "metadata": {
        "id": "SnL4rP7TlJ4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the instance of new model\n",
        "\n",
        "model_1 = FashionModel_V2(input_shape=784,\n",
        "                          hidden_units=10,\n",
        "                          output_shape=10).to(device)"
      ],
      "metadata": {
        "id": "kxPQpcmPlJ4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def train_step(model: nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               device: torch.device,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               epochs: int):\n",
        "\n",
        "  train_loss = 0\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "\n",
        "    train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      #1 Forward pass\n",
        "      y_pred = model(X)\n",
        "\n",
        "      #2 Calcualte loss on one batch of data\n",
        "      loss = loss_fn(y_pred, y)\n",
        "      train_loss += loss.item()\n",
        "\n",
        "      #3 Optimizer zero grad\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      #4 loss backward\n",
        "      loss.backward()\n",
        "\n",
        "      #5 optimizer step\n",
        "      optimizer.step()\n",
        "\n",
        "    train_loss /= len(dataloader)\n",
        "    print(f\"Epoch: {epoch}\\n-------\")\n",
        "    print(f\"Loss: {train_loss}\")"
      ],
      "metadata": {
        "id": "2fQldarFlJ4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model(model = model_1,\n",
        "           data_loader = test_dataloader,\n",
        "           loss_fn = loss_fn,\n",
        "           accuracy_fn = accuracy_fn,\n",
        "           device = device)"
      ],
      "metadata": {
        "id": "VgnvZVf6lJ4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(params=model_1.parameters(), lr=0.1)\n",
        "\n",
        "train_step(model = model_1,\n",
        "           dataloader = train_dataloader,\n",
        "           loss_fn = loss_fn,\n",
        "           device = device,\n",
        "           epochs = 3)"
      ],
      "metadata": {
        "id": "ia1J3AE_lJ4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 2. Build a CNN\n",
        "\n",
        "CNNs are deep learning models designe to process data with a grid like structure.\n",
        "\n",
        "Also known as CovNets and are known to find patterns within visual data. It is going to compress the image into its most generalizable patterns. And that feature layer is eventuall ygoing to result in a\n",
        "\n",
        "Similar to what we've just built. We're just going to use different layers. E.g., convolutional layers"
      ],
      "metadata": {
        "id": "0tPXzi_MlJ4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionCNN(nn.Module):\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        #a convolution layer is going to compress the image\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3, #defines the ?x? square that it is going to provide the operation over\n",
        "                  stride=1, #the kernal is going to move by one pixel to compress the image\n",
        "                  padding=1), #adds padding to the image to perform computations over the edges and corners\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, #it is going to a ?x? kernal to return the max number\n",
        "                     stride=2)\n",
        "    )\n",
        "    self.conv_block_3 = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*7*7, out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv_block_3(self.conv_block_2(self.conv_block_1(x)))"
      ],
      "metadata": {
        "id": "ikylP8bIlJ4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = FashionCNN(input_shape=1, #use 1 because we only have one color channel\n",
        "                     hidden_units=10,\n",
        "                     output_shape=10 #use because we have 10 categories of images\n",
        "                     ).to(device)"
      ],
      "metadata": {
        "id": "CMzKRFgilJ4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set up a loss function and an optimiser\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_2.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "7GlLpBQ8lJ4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "train_time_start_model_2 = timer()\n",
        "\n",
        "train_step(model = model_2,\n",
        "           dataloader = train_dataloader,\n",
        "           loss_fn = loss_fn,\n",
        "           device = device,\n",
        "           optimizer = optimizer,\n",
        "           epochs = 3)\n",
        "\n",
        "train_time_end_model_2 = timer()\n",
        "print(f\"Total train time {train_time_end_model_2 - train_time_start_model_2}\")"
      ],
      "metadata": {
        "id": "aK4dky3blJ4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model(model = model_2,\n",
        "           data_loader = test_dataloader,\n",
        "           loss_fn = loss_fn,\n",
        "           accuracy_fn = accuracy_fn,\n",
        "           device = device)"
      ],
      "metadata": {
        "id": "bQsdvlPDlJ4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making predictions iwth our data\n",
        "def make_predictions(model: torch.nn.Module,\n",
        "                     data: list,\n",
        "                     device: torch.device):\n",
        "  pred_probs = []\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for sample in data:\n",
        "      sample = torch.unsqueeze(sample, dim=0).to(device)\n",
        "      pred_logit = model(sample)\n",
        "      pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
        "      pred_probs.append(pred_prob.cpu())\n",
        "  return torch.stack(pred_probs)"
      ],
      "metadata": {
        "id": "XU6YX9_5lJ4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "for sample, label in random.sample(list(test_data), k=10):\n",
        "  test_samples.append(sample)\n",
        "  test_labels.append(label)\n",
        "\n",
        "test_samples[0].shape"
      ],
      "metadata": {
        "id": "Xdw_KLT6lJ4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_samples[0].squeeze(), cmap=\"grey\")"
      ],
      "metadata": {
        "id": "BFsUxAz3lJ4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probs = make_predictions(model = model_2, data = test_samples, device = device)\n",
        "pred_classes = pred_probs.argmax(dim=1)\n",
        "class_names = train_data.classes\n",
        "pred_classes"
      ],
      "metadata": {
        "id": "tgIuLY0ElJ4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(9,9))\n",
        "nrows = 3\n",
        "ncols = 3\n",
        "for i, sample in enumerate(test_samples):\n",
        "  plt.subplot(nrows, ncols, i+1)\n",
        "  plt.imshow(sample.squeeze(), cmap=\"grey\")\n",
        "\n",
        "  pred_label = class_names[pred_classes[i]]\n",
        "  truth_label = class_names[test_labels[i]]\n",
        "\n",
        "  title_text = f\"Pred {pred_label} | Truth: {truth_label}\"\n",
        "\n",
        "  if pred_label == truth_label:\n",
        "    plt.title(title_text, fontsize = 10, c=\"g\")\n",
        "  else:\n",
        "    plt.title(title_text, fontsize = 10, c = \"r\")\n",
        "\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "vcIBzC0hlJ4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Confusion Matrices\n",
        "\n",
        "A confusion matrix is great for further prediction evaluation\n",
        "\n",
        "Maybe checkout the book: Machine Learning with PyTorch and Scikit-Learn\n",
        "\n",
        "A confusion matrix consists of the True positives/negatives and false positives/negatives\n"
      ],
      "metadata": {
        "id": "H_AsJQ3_lJ4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#installing package torchmetrics and mlxtend\n",
        "!pip install torchmetrics -U mlxtend\n",
        "import torchmetrics\n",
        "import mlxtend"
      ],
      "metadata": {
        "id": "H4OgfjWqlJ4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "y_trues = []\n",
        "y_preds = []\n",
        "model_2.eval()\n",
        "with torch.inference_mode():\n",
        "  for X, y in tqdm(test_dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    y_logit = model_2(X)\n",
        "    y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1)\n",
        "    y_preds.append(y_pred.cpu())\n",
        "    y_trues.append(y.cpu())\n",
        "\n",
        "y_pred_tensor = torch.cat(y_preds)\n",
        "y_true_tensor = torch.cat(y_trues)"
      ],
      "metadata": {
        "id": "MRyNlz36lJ4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "#2. Setup confusion instance and compare predictions to targets\n",
        "confmat = ConfusionMatrix(num_classes = len(class_names),\n",
        "                          task = \"multiclass\")\n",
        "confmat_tensor = confmat(preds=y_pred_tensor,\n",
        "                         target=y_true_tensor)\n",
        "\n",
        "#3. Plot the confusion matrix\n",
        "fig, ax = plot_confusion_matrix(conf_mat=confmat_tensor.numpy(),\n",
        "                                figsize=(10,8),\n",
        "                                class_names=class_names,\n",
        "                                cmap=plt.cm.Blues)\n",
        "\n"
      ],
      "metadata": {
        "id": "c6Xb_kFklJ4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving and Loading best performing model"
      ],
      "metadata": {
        "id": "okjkmI5XlJ4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "MODEL_NAME = \"0.3_pytorch_cv_model_2.pth\"\n",
        "\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_2.state_dict(),\n",
        "           f = MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "v1mH6RY7lJ4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_2 = FashionCNN(input_shape=1,\n",
        "                            hidden_units=10,\n",
        "                            output_shape=10).to(device)\n",
        "\n",
        "loaded_model_2.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
        "\n",
        "eval_model(model = loaded_model_2,\n",
        "           data_loader = test_dataloader,\n",
        "           loss_fn = loss_fn,\n",
        "           accuracy_fn = accuracy_fn,\n",
        "           device = device)"
      ],
      "metadata": {
        "id": "chH_9kyNlJ4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JiHvjJLSlJ4b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}